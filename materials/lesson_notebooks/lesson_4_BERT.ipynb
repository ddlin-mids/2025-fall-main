{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jN7tT2jvuYxo"
   },
   "source": [
    "# Lesson 4 Notebook: BERT Endeavors\n",
    "\n",
    "**Description:** After some setup for our standard IMDB movie classification task we will explore BERT (obtained from the [Huggingface Transformer library](https://huggingface.co/docs/transformers/index)) and apply it to text classification.\n",
    "\n",
    "<a id = 'returnToTop'></a>\n",
    "\n",
    "## Notebook Contents\n",
    "  * 1. [Setup](#setup)\n",
    "  * 2. [Data Acquisition](#dataAcquisition)  \n",
    "  * 3. [BERT Basics](#bertBasics)\n",
    "    * 3.1 [Tokenization](#tokenization)\n",
    "    * 3.2 [Model Structure & Output](#modelOutput)\n",
    "    * 3.3 [Context Based Embeddings with BERT](#contextualEmbeddings)\n",
    "  * 4. [Text Classification with BERT (using the Pooler Output)](#BERTClassification)\n",
    "    * 4.1 [Classification Model Setup](#modelSetup)\n",
    "    * 4.2 [Model Training](#modelTraining)\n",
    "    * 4.3 [Class Exercise](#classExercise)\n",
    "\n",
    "  [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/datasci-w266/2025-fall-main/blob/master/materials/lesson_notebooks/lesson_4_BERT.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "knuH9pWDuYxs"
   },
   "source": [
    "[Return to Top](#returnToTop)  \n",
    "<a id = 'setup'></a>\n",
    "\n",
    "## 1. Setup\n",
    "\n",
    "This notebook requires the Huggingface transformers package and a dataset that you must download and then store locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbeFE53buYxu",
    "outputId": "a78e986f-82a6-48fc-dda1-70ee35928b52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/84.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers\n",
    "!pip install -q torchinfo\n",
    "!pip install -U -q datasets fsspec huggingface_hub # Hugging Face's dataset library\n",
    "!pip install -q datasets\n",
    "!pip install -q evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UEuJaUNnuYxw"
   },
   "source": [
    "Ready to do the imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tB-wHngguYxx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import transformers\n",
    "import evaluate\n",
    "\n",
    "from datasets import load_dataset\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RW0-oUC9P5B8"
   },
   "source": [
    "For the Transformer library we need to import the **tokenizer**, the pre-trained **model**, and a **trainer** class plus **trainer arguments** to do the fine-tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Zn-icS7sP5pj"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_Bw3EB5Vwye"
   },
   "source": [
    "A small function calculating the cosine similarity may also come in handy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "g3nNnV2_Vw_L"
   },
   "outputs": [],
   "source": [
    "def cosine_similarities(vecs):\n",
    "    for v_1 in vecs:\n",
    "        similarities = ''\n",
    "        for v_2 in vecs:\n",
    "            similarities += ('\\t' + str(np.dot(v_1, v_2)/np.sqrt(np.dot(v_1, v_1) * np.dot(v_2, v_2)))[:4])\n",
    "        print(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVV7cXFjuYx4"
   },
   "source": [
    "[Return to Top](#returnToTop)  \n",
    "<a id = 'dataAcquisition'></a>\n",
    "\n",
    "## 2. Data Acquisition\n",
    "\n",
    "We will use the IMDB dataset delivered as part of the Huggingface datasets library, and split into training and test sets. For expedience, we will limit ourselves in terms of train and test examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "3f6cb247734b4da192a811029f732718",
      "8b7d01fe7f4041a6b304a7eec69bd966",
      "a8668d7bd3d342b884b3b144d81c9667",
      "38e9da2170c1462fbb9107f587f7f21a",
      "8ad4792a324649189f9f7bf8429880b5",
      "69f69d19fccd4eab8d44e05b815c39ff",
      "27a32a58e4b3414db5a64ce3e12f3c36",
      "fdf32c61765f4efe80e3dac57691211e",
      "0dc2e4d360554f54bb88e02dd8648f40",
      "d954ff56f52345c3acfcb3c59a9a1b30",
      "d025c08925f34833a684c667a4679274",
      "214f6e059bc94788b86773c4ac8d7dbe",
      "7105cbfaebd94635af080706334d583e",
      "ddf2ceae58494e2ab4c8f67dd2b2d050",
      "921c29c7e8db429c9c5163f4fb5552b5",
      "89158068ce6c4f759b22d4b865681dfa",
      "eb13b528276e4607b8ecfa02fcbbc232",
      "d11b311a99b44b6ca4890a46b1cccdfb",
      "b6979ff9f451467ca610dec616e02569",
      "97f7449880df42719143fb8334ab9bbc",
      "847f15be26ed4eb6ae9a827ad096fe92",
      "17419d6c06944039978ebba2fb69f377",
      "13f6c0d3e31149279485a0b950268243",
      "90480ee5d0994f4885423be3701a6260",
      "521cb4203c6b48bbac3e4c0534fa02a7",
      "95a544057a0d4527ad74df231b2b1242",
      "2b007f5650314e8e95f25c206ab85ee1",
      "c91db0aa3a4b4138aa8eebf4003c24fe",
      "ec78a86f40d043f7b7c82b40c21274f9",
      "8d7822975d5a4618841994f4d25f76f7",
      "669d54cb500b4eabba27867e00bfb892",
      "70d40afc52594b48be0c0ad0cbf10a89",
      "f2756f9f0a6745569defea2e4335998c",
      "d37bebadc25248a7a3446e46f3241836",
      "46deeb1b041b4b118da4b4c24c519082",
      "1017b78901b44a8db2baeaeb6a8fcc78",
      "56bb39db04444377ab0cd23d52f4c818",
      "8abeddac6f3944b69c7bc6982b8cc743",
      "ff7cf3ae3730404bb93b1cd20c0fa7b0",
      "be10257848ff4728b98a18463029ad56",
      "5bd5a944862444cfab87cc86205f6837",
      "7d7ef3894c374525bf0f1a72607635d3",
      "23c4ceca35844c989df900a239c14159",
      "5c40a541bf67430eb8f6c81607dfc394",
      "4e1391e74cfc476c826bc184a25b840e",
      "5e8995f503024971b685a57cd322f031",
      "0282d32fb3e641159ff6a13cc316c940",
      "7a81362c455043eca1852589584bd40a",
      "bc74d7a48be847ea914d6da6ed2c1005",
      "554dd3e8b1774497a37df4128844c858",
      "096b4cfec8784617ae91912f79bd8ad6",
      "7cc96d7244f94ea4bb231f0f96342daa",
      "bfd1da43c007403a8b7b5195ebd4dc40",
      "d6725bf33c6642e8b875af740177d91a",
      "91f33929abbc43d8852600feef90ee50",
      "06313b81d548447fb61785973c5a7c2d",
      "e13f5c403c3b4b94b19b232785b8127c",
      "03e55b37a24f4d83a839e24cd242e85f",
      "c06e802df1db4e30ba80ced3f2956196",
      "fcaac79536904d40b7be52372f171ced",
      "4e698efda8c54d5187c34e54ffcf9a04",
      "e91d5801a04942e2a8bfb2a6ed64130a",
      "e000c041b3574412aae3c1ea703d0dfc",
      "11194c2d8f6b4d9eb4db5e9193c40ec8",
      "07858c9813414a16b15082cddd34ad6c",
      "5488726f74214c3485af20e54ee6fab2",
      "f1565ac4b4454e8ba7f95936b34fdce2",
      "396956ee3c914975b5d6f4a59088c904",
      "93699842c3aa40319eceb14fade4c3e6",
      "d1e105142f614a90b3bc93dc29797ba1",
      "31c99a5a23ef459b83ab93339cc0d27a",
      "06b772a9403d4972b31e7626153d540d",
      "1ed2c83eaa8c47ce818af2fe55389c39",
      "0dbf8d8574da418a8072e1a1c787f340",
      "6e9ca3c55ce8464399081221e1a14c25",
      "5ac7fb78d21b491fb84b3482431e077b",
      "ace65b2b487c42fb899969183e012b58"
     ]
    },
    "id": "DEsvBbocuYx4",
    "outputId": "4f7139a9-4940-4a3d-d07d-05f74ca9072b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6cb247734b4da192a811029f732718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "214f6e059bc94788b86773c4ac8d7dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f6c0d3e31149279485a0b950268243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37bebadc25248a7a3446e46f3241836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "plain_text/unsupervised-00000-of-00001.p(…):   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1391e74cfc476c826bc184a25b840e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06313b81d548447fb61785973c5a7c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1565ac4b4454e8ba7f95936b34fdce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imdb_dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hVXmgm7YuYx4",
    "outputId": "50210da8-c88d-4638-a390-873eab5f7169"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at what's in the dataset\n",
    "imdb_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "bz2tFw9VuYx4",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "9cf36a97-c57a-4b42-9e1a-6e5ba8ad7173"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn't have much of a plot.\n",
      "0\n",
      "\n",
      "\"I Am Curious: Yellow\" is a risible and pretentious steaming pile. It doesn't matter what one's political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn't true. I've seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don't exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we're treated to the site of Vincent Gallo's throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \"double-standard\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won't see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women's bodies.\n",
      "0\n",
      "\n",
      "If only to avoid making this type of film in the future. This film is interesting as an experiment but tells no cogent story.<br /><br />One might feel virtuous for sitting thru it because it touches on so many IMPORTANT issues but it does so without any discernable motive. The viewer comes away with no new perspectives (unless one comes up with one while one's mind wanders, as it will invariably do during this pointless film).<br /><br />One might better spend one's time staring out a window at a tree growing.<br /><br />\n",
      "0\n",
      "\n",
      "This film was probably inspired by Godard's Masculin, féminin and I urge you to see that film instead.<br /><br />The film has two strong elements and those are, (1) the realistic acting (2) the impressive, undeservedly good, photo. Apart from that, what strikes me most is the endless stream of silliness. Lena Nyman has to be most annoying actress in the world. She acts so stupid and with all the nudity in this film,...it's unattractive. Comparing to Godard's film, intellectuality has been replaced with stupidity. Without going too far on this subject, I would say that follows from the difference in ideals between the French and the Swedish society.<br /><br />A movie of its time, and place. 2/10.\n",
      "0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at the first few examples\n",
    "for i in range(4):\n",
    "  print(imdb_dataset['train']['text'][i])\n",
    "  print(imdb_dataset['train']['label'][i])\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1fD5Ah2muYx5",
    "outputId": "029b239f-c01f-419a-ac99-aa26f16adffb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the label names\n",
    "imdb_dataset['train'].features['label'].names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyUVciGOQ72E"
   },
   "source": [
    "[Return to Top](#returnToTop)  \n",
    "<a id = 'bertBasics'></a>\n",
    "## 3. BERT Basics\n",
    "\n",
    "We now need to settle on the pre-trained BERT model we want to use. We will leverage **'bert-base-cased'**.\n",
    "\n",
    "We need to load the model and corresponding tokenizer. Let's start with the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "4d29841afe6d47f397c6223bd2e9d5be",
      "e61f46e3412a4491a705225321b9d7ae",
      "b27178f2d01941b49b313a94f908f3f9",
      "c65030653b4b4fffa2d1b97d22787ab8",
      "f20d610d412e4bd08b34232bf9448f3a",
      "095aafbd072040999250582f99d03a6a",
      "f9e5165d925d448fb783271fe9b71584",
      "d3346d6237d441548b195a6fd232230a",
      "ab895a1952f34a42b6e64472be6874a7",
      "e4331cdc958141d498a99bfcb0ec53c4",
      "c53394c47d32484faf61d0e0ee0c194f",
      "ca17d944f88f4354b3bd5515ec3200d2",
      "76779ab6b77a47199dd9ed07ff98c3f9",
      "b60e5f7cf6744bb385a226db344d73c8",
      "2ef58bcf525d4e29990933af379d72e9",
      "eb8dd589eb124400b716b5903b92a740",
      "35e666dbed384f4a8680190415c9adb2",
      "7a976d3de6bd4f60a393fb4b0323e052",
      "5e9678883323440faacf43f5b89c3e2d",
      "53caef3a882b40b3a0af198e679ee7ac",
      "b125377620b84a36b70f724a15e0ab29",
      "dd523d6824fe4ba9ba4a65c1d9773d3c",
      "ec8d8d3320d44c689c35050e44e9c206",
      "9f28322ccef74870a2225db1b150a518",
      "990aee24f3544de089a8da0473cba7e2",
      "8919171c0a074203bd1b05d60556237e",
      "35d5b7338f2d48e4adc71c91c12df84e",
      "25c019890ae94e0cba0322afd3773e43",
      "a5216ec731aa4e4cb993cc787c79f4b6",
      "b1269fb274554400a0c7b3bfb389ba5e",
      "c7dc2a7c3bc8438382bf1ad5c098d9bc",
      "37d2e0e616b543c4b5ca18a56f01dac5",
      "bf14b8f98d034eaab3d9431d591ab874",
      "b932bd3e5f72456dbead863fdc42b29c",
      "7c50a970106f4faaa152d840cdcc1f0b",
      "fb5c8684702b4d94bfdf1fd8ad5d8b53",
      "cfd98fe8ca044f32bee6f783e5c68a69",
      "963cc23a72dd4b0c862882a61425387d",
      "2d569516ce1143139d8549f38b378ab1",
      "aff338e1e3094015bb06b80051d4b6b1",
      "653d305782b94fa882064825328871bb",
      "c27cb700096540c28da94beb9d043783",
      "d5079d4727ba4c249728f955e24d096b",
      "3e7fdd1bcdaa4872823a96f5afaba172"
     ]
    },
    "id": "6VvVL8deRhtY",
    "outputId": "4a0935dc-0af7-4a85-cbe3-aaef07639893"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d29841afe6d47f397c6223bd2e9d5be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca17d944f88f4354b3bd5515ec3200d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8d8d3320d44c689c35050e44e9c206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b932bd3e5f72456dbead863fdc42b29c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint = 'bert-base-cased'\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGwBMcXDR235"
   },
   "source": [
    "[Return to Top](#returnToTop)  \n",
    "<a id = 'tokenization'></a>\n",
    "\n",
    "### 3.1 Tokenization\n",
    "\n",
    "Tokenization with BERT is interesting. To minimize the number of unknown words, BERT (like most pre-trained transformer models) uses a **subword** model for tokenization. We will see what that means in a second.\n",
    "\n",
    "Let's start with something simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2CZ5FbncSYtN",
    "outputId": "2ada5505-2404-446f-8c20-e884065b8975"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'is', 'great', '!']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.tokenize('This is great!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Egd6BXhScvv"
   },
   "source": [
    "Ok, that is as expected. What about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JWZlCdaiSdQy",
    "outputId": "1b6984ac-f1ec-4504-d59a-789e112e7c68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'tree', 'is', '125', '##3', 'years', 'old', '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.tokenize('This tree is 1253 years old.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6ropVVNSn4p"
   },
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m8yW5TB8SoCN",
    "outputId": "bca1c7c2-746d-4246-a01c-61976302d2b9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P', '##ne', '##um', '##onia', 'can', 'be', 'very', 'serious', '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer.tokenize('Pneumonia can be very serious.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apDHuWYCSxGb"
   },
   "source": [
    "Ouch! Many more complex terms are not in BERT's vocabulary and are split up.\n",
    "\n",
    "**Question:** in what type of NLP problems can this lead to complications?\n",
    "\n",
    "Next, how do we generate the BERT input with its tokenizer? Fortunately, by now Huggingface's tokenizer implementation makes this rather straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RbwyQg5uRhwU",
    "outputId": "f8fb9567-211f-4b60-a1ea-e33106e11774"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1188, 1110, 1632, 106, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer(['This is great!'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PWKc757TXvs"
   },
   "source": [
    "To make sure we do this correctly though we may want to specify that we want to have the inputs for TensorFlow (vs. PyTorch), and we may want to do some padding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KGJVehAZRhy7",
    "outputId": "eff725a8-d952-438e-9444-0ff049198f2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1188, 1110, 1632,  106,  102,    0,    0,    0,    0],\n",
       "        [ 101, 1188, 1110, 6434,  106,  102,    0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_input = bert_tokenizer.batch_encode_plus(\n",
    "    ['This is great!', 'This is terrible!'],\n",
    "    max_length=10,\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "bert_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uflk2zNpmdzA"
   },
   "source": [
    "What do we notice? Look at shapes and values. Does everything make sense?\n",
    "\n",
    "**Question**: What is the input_id of the CLS token? What is the input_id of the SEP token?\n",
    "\n",
    "We'll use the tokenizer to preprocess our input text. We can define a function that takes each movie review and turns it into the inputs needed for the BERT model. Then we'll map that function onto our training and validation datasets.\n",
    "\n",
    "We'll restrict the number of examples we use during the live session, so that the training goes more quickly, but you can try using the full dataset on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "AByosWXkuxP-"
   },
   "outputs": [],
   "source": [
    "max_length = 128\n",
    "\n",
    "def preprocess_imdb(data):\n",
    "    review_text = data['text']\n",
    "\n",
    "    encoded = bert_tokenizer.batch_encode_plus(\n",
    "            review_text,\n",
    "            max_length=max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "7f46f13e426e4b718f9d80a0473b45f9",
      "f457fb8b511540a593a5a52c02d0503a",
      "ab20a0cf501e435d83ad398245bc26da",
      "6d15b1dd3173400db577968dc6695522",
      "5f9f652580b549b28a54afac1e2949b6",
      "7395515bb4b94d1f822fed747f8bf7f1",
      "35d87889e89b4b8797338f13dc437fc7",
      "20d12cfb244a478bb94bfccc2dda11d1",
      "ca83001ea16f43e9a886402d58567c26",
      "b8b957a7f82948738d7133f6945c7e23",
      "9dbe119fefc04fe6b0eb1cecd6362d9b",
      "0523770142a34b2aa4dd4aaf4c3c77c3",
      "1a48d7fbd4b8468cbc2c1e8cc29629b0",
      "8de9f169d0a24354a9623b15caeab73b",
      "701596380217442ebb446a7ceedbbc3e",
      "14db27de6bb542f088e6d139ec75d94d",
      "ce73df4245cf4168b7e11380a28e53aa",
      "a34b78d3c2f84feaaee5e3f578e4cac1",
      "2da6645df0ce4e8b86a6deb6e7fe8b4f",
      "e79500fe5b9e4b3c9579520aabfbd79f",
      "0f69f09b43fd4294992692eba7326ff3",
      "60f91df5b703414e9c6b197c559f977f"
     ]
    },
    "id": "xXbblWM9vI9Z",
    "outputId": "532c418b-152c-4458-9aca-66ec24732680"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f46f13e426e4b718f9d80a0473b45f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0523770142a34b2aa4dd4aaf4c3c77c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_train = 5000  # There are 25,000 available; we'll use less in the live session\n",
    "num_dev = 500  # There are another 25,000 in the \"test\" split, which we'll use for validation, since the remaining split doesn't have labels\n",
    "\n",
    "imdb_train_dataset = imdb_dataset['train'].shuffle().select(range(num_train)).map(preprocess_imdb, batched=True)\n",
    "imdb_dev_dataset = imdb_dataset['test'].shuffle().select(range(num_dev)).map(preprocess_imdb, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_L_5X9K-Yr24",
    "outputId": "fb4dd903-8d7c-4ccc-dba5-0ad82fdccdf3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBzUOfaWTwoa"
   },
   "source": [
    "[Return to Top](#returnToTop)  \n",
    "<a id = 'modelOutput'></a>\n",
    "\n",
    "### 3.2 Model Structure & Output\n",
    "\n",
    "Where we have familiarized ourselves with the tokenization, we can now turn to the model and its output.\n",
    "\n",
    "Let's start by using the basic BertModel class. This class loads only the pre-trained part of the model that we'll use, up until the last hidden layer. We don't want the output layers used in pre-training, since we won't be doing those tasks (i.e. masked token prediction or next sentence prediction).\n",
    "\n",
    "We can look at the model's internal weight matrices, to see what's in the pre-trained layers we've loaded. These are named, and they should be familiar, based on our knowledge of the BERT model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "565e93f3e87a4efa81af0aac34ad60e0",
      "1274df23e0634b65a26d28303813f2d0",
      "a028b87393f9410abab738cad2073493",
      "fa4741125f314d33a1e43fc14370b9c3",
      "76bbec1ecdff4c8f93383a26a47f840c",
      "f2a17abe70d449d687277a1a2cefa1bd",
      "9eb0cb7f76ef4bfeb0d9a808792c223c",
      "d2122ad56fe042f796613228d2fd7bea",
      "b21c6d477cd54bd6be60b2d389f7be16",
      "c709fc9b0b794fddaf01aae3f55d164f",
      "8b9ac9f02b0848f2b77971a0574b68b9"
     ]
    },
    "id": "78onR63vkomz",
    "outputId": "3acb2617-7f5e-4691-d3a0-7023c810a472"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "565e93f3e87a4efa81af0aac34ad60e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GFc8_mlAbVMx",
    "outputId": "5fb8f50d-9dbe-4c05-bfea-e82bf2265466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.word_embeddings.weight\n",
      "embeddings.position_embeddings.weight\n",
      "embeddings.token_type_embeddings.weight\n",
      "embeddings.LayerNorm.weight\n",
      "embeddings.LayerNorm.bias\n",
      "encoder.layer.0.attention.self.query.weight\n",
      "encoder.layer.0.attention.self.query.bias\n",
      "encoder.layer.0.attention.self.key.weight\n",
      "encoder.layer.0.attention.self.key.bias\n",
      "encoder.layer.0.attention.self.value.weight\n",
      "encoder.layer.0.attention.self.value.bias\n",
      "encoder.layer.0.attention.output.dense.weight\n",
      "encoder.layer.0.attention.output.dense.bias\n",
      "encoder.layer.0.attention.output.LayerNorm.weight\n",
      "encoder.layer.0.attention.output.LayerNorm.bias\n",
      "encoder.layer.0.intermediate.dense.weight\n",
      "encoder.layer.0.intermediate.dense.bias\n",
      "encoder.layer.0.output.dense.weight\n",
      "encoder.layer.0.output.dense.bias\n",
      "encoder.layer.0.output.LayerNorm.weight\n",
      "encoder.layer.0.output.LayerNorm.bias\n",
      "encoder.layer.1.attention.self.query.weight\n",
      "encoder.layer.1.attention.self.query.bias\n",
      "encoder.layer.1.attention.self.key.weight\n",
      "encoder.layer.1.attention.self.key.bias\n",
      "encoder.layer.1.attention.self.value.weight\n",
      "encoder.layer.1.attention.self.value.bias\n",
      "encoder.layer.1.attention.output.dense.weight\n",
      "encoder.layer.1.attention.output.dense.bias\n",
      "encoder.layer.1.attention.output.LayerNorm.weight\n",
      "encoder.layer.1.attention.output.LayerNorm.bias\n",
      "encoder.layer.1.intermediate.dense.weight\n",
      "encoder.layer.1.intermediate.dense.bias\n",
      "encoder.layer.1.output.dense.weight\n",
      "encoder.layer.1.output.dense.bias\n",
      "encoder.layer.1.output.LayerNorm.weight\n",
      "encoder.layer.1.output.LayerNorm.bias\n",
      "encoder.layer.2.attention.self.query.weight\n",
      "encoder.layer.2.attention.self.query.bias\n",
      "encoder.layer.2.attention.self.key.weight\n",
      "encoder.layer.2.attention.self.key.bias\n",
      "encoder.layer.2.attention.self.value.weight\n",
      "encoder.layer.2.attention.self.value.bias\n",
      "encoder.layer.2.attention.output.dense.weight\n",
      "encoder.layer.2.attention.output.dense.bias\n",
      "encoder.layer.2.attention.output.LayerNorm.weight\n",
      "encoder.layer.2.attention.output.LayerNorm.bias\n",
      "encoder.layer.2.intermediate.dense.weight\n",
      "encoder.layer.2.intermediate.dense.bias\n",
      "encoder.layer.2.output.dense.weight\n",
      "encoder.layer.2.output.dense.bias\n",
      "encoder.layer.2.output.LayerNorm.weight\n",
      "encoder.layer.2.output.LayerNorm.bias\n",
      "encoder.layer.3.attention.self.query.weight\n",
      "encoder.layer.3.attention.self.query.bias\n",
      "encoder.layer.3.attention.self.key.weight\n",
      "encoder.layer.3.attention.self.key.bias\n",
      "encoder.layer.3.attention.self.value.weight\n",
      "encoder.layer.3.attention.self.value.bias\n",
      "encoder.layer.3.attention.output.dense.weight\n",
      "encoder.layer.3.attention.output.dense.bias\n",
      "encoder.layer.3.attention.output.LayerNorm.weight\n",
      "encoder.layer.3.attention.output.LayerNorm.bias\n",
      "encoder.layer.3.intermediate.dense.weight\n",
      "encoder.layer.3.intermediate.dense.bias\n",
      "encoder.layer.3.output.dense.weight\n",
      "encoder.layer.3.output.dense.bias\n",
      "encoder.layer.3.output.LayerNorm.weight\n",
      "encoder.layer.3.output.LayerNorm.bias\n",
      "encoder.layer.4.attention.self.query.weight\n",
      "encoder.layer.4.attention.self.query.bias\n",
      "encoder.layer.4.attention.self.key.weight\n",
      "encoder.layer.4.attention.self.key.bias\n",
      "encoder.layer.4.attention.self.value.weight\n",
      "encoder.layer.4.attention.self.value.bias\n",
      "encoder.layer.4.attention.output.dense.weight\n",
      "encoder.layer.4.attention.output.dense.bias\n",
      "encoder.layer.4.attention.output.LayerNorm.weight\n",
      "encoder.layer.4.attention.output.LayerNorm.bias\n",
      "encoder.layer.4.intermediate.dense.weight\n",
      "encoder.layer.4.intermediate.dense.bias\n",
      "encoder.layer.4.output.dense.weight\n",
      "encoder.layer.4.output.dense.bias\n",
      "encoder.layer.4.output.LayerNorm.weight\n",
      "encoder.layer.4.output.LayerNorm.bias\n",
      "encoder.layer.5.attention.self.query.weight\n",
      "encoder.layer.5.attention.self.query.bias\n",
      "encoder.layer.5.attention.self.key.weight\n",
      "encoder.layer.5.attention.self.key.bias\n",
      "encoder.layer.5.attention.self.value.weight\n",
      "encoder.layer.5.attention.self.value.bias\n",
      "encoder.layer.5.attention.output.dense.weight\n",
      "encoder.layer.5.attention.output.dense.bias\n",
      "encoder.layer.5.attention.output.LayerNorm.weight\n",
      "encoder.layer.5.attention.output.LayerNorm.bias\n",
      "encoder.layer.5.intermediate.dense.weight\n",
      "encoder.layer.5.intermediate.dense.bias\n",
      "encoder.layer.5.output.dense.weight\n",
      "encoder.layer.5.output.dense.bias\n",
      "encoder.layer.5.output.LayerNorm.weight\n",
      "encoder.layer.5.output.LayerNorm.bias\n",
      "encoder.layer.6.attention.self.query.weight\n",
      "encoder.layer.6.attention.self.query.bias\n",
      "encoder.layer.6.attention.self.key.weight\n",
      "encoder.layer.6.attention.self.key.bias\n",
      "encoder.layer.6.attention.self.value.weight\n",
      "encoder.layer.6.attention.self.value.bias\n",
      "encoder.layer.6.attention.output.dense.weight\n",
      "encoder.layer.6.attention.output.dense.bias\n",
      "encoder.layer.6.attention.output.LayerNorm.weight\n",
      "encoder.layer.6.attention.output.LayerNorm.bias\n",
      "encoder.layer.6.intermediate.dense.weight\n",
      "encoder.layer.6.intermediate.dense.bias\n",
      "encoder.layer.6.output.dense.weight\n",
      "encoder.layer.6.output.dense.bias\n",
      "encoder.layer.6.output.LayerNorm.weight\n",
      "encoder.layer.6.output.LayerNorm.bias\n",
      "encoder.layer.7.attention.self.query.weight\n",
      "encoder.layer.7.attention.self.query.bias\n",
      "encoder.layer.7.attention.self.key.weight\n",
      "encoder.layer.7.attention.self.key.bias\n",
      "encoder.layer.7.attention.self.value.weight\n",
      "encoder.layer.7.attention.self.value.bias\n",
      "encoder.layer.7.attention.output.dense.weight\n",
      "encoder.layer.7.attention.output.dense.bias\n",
      "encoder.layer.7.attention.output.LayerNorm.weight\n",
      "encoder.layer.7.attention.output.LayerNorm.bias\n",
      "encoder.layer.7.intermediate.dense.weight\n",
      "encoder.layer.7.intermediate.dense.bias\n",
      "encoder.layer.7.output.dense.weight\n",
      "encoder.layer.7.output.dense.bias\n",
      "encoder.layer.7.output.LayerNorm.weight\n",
      "encoder.layer.7.output.LayerNorm.bias\n",
      "encoder.layer.8.attention.self.query.weight\n",
      "encoder.layer.8.attention.self.query.bias\n",
      "encoder.layer.8.attention.self.key.weight\n",
      "encoder.layer.8.attention.self.key.bias\n",
      "encoder.layer.8.attention.self.value.weight\n",
      "encoder.layer.8.attention.self.value.bias\n",
      "encoder.layer.8.attention.output.dense.weight\n",
      "encoder.layer.8.attention.output.dense.bias\n",
      "encoder.layer.8.attention.output.LayerNorm.weight\n",
      "encoder.layer.8.attention.output.LayerNorm.bias\n",
      "encoder.layer.8.intermediate.dense.weight\n",
      "encoder.layer.8.intermediate.dense.bias\n",
      "encoder.layer.8.output.dense.weight\n",
      "encoder.layer.8.output.dense.bias\n",
      "encoder.layer.8.output.LayerNorm.weight\n",
      "encoder.layer.8.output.LayerNorm.bias\n",
      "encoder.layer.9.attention.self.query.weight\n",
      "encoder.layer.9.attention.self.query.bias\n",
      "encoder.layer.9.attention.self.key.weight\n",
      "encoder.layer.9.attention.self.key.bias\n",
      "encoder.layer.9.attention.self.value.weight\n",
      "encoder.layer.9.attention.self.value.bias\n",
      "encoder.layer.9.attention.output.dense.weight\n",
      "encoder.layer.9.attention.output.dense.bias\n",
      "encoder.layer.9.attention.output.LayerNorm.weight\n",
      "encoder.layer.9.attention.output.LayerNorm.bias\n",
      "encoder.layer.9.intermediate.dense.weight\n",
      "encoder.layer.9.intermediate.dense.bias\n",
      "encoder.layer.9.output.dense.weight\n",
      "encoder.layer.9.output.dense.bias\n",
      "encoder.layer.9.output.LayerNorm.weight\n",
      "encoder.layer.9.output.LayerNorm.bias\n",
      "encoder.layer.10.attention.self.query.weight\n",
      "encoder.layer.10.attention.self.query.bias\n",
      "encoder.layer.10.attention.self.key.weight\n",
      "encoder.layer.10.attention.self.key.bias\n",
      "encoder.layer.10.attention.self.value.weight\n",
      "encoder.layer.10.attention.self.value.bias\n",
      "encoder.layer.10.attention.output.dense.weight\n",
      "encoder.layer.10.attention.output.dense.bias\n",
      "encoder.layer.10.attention.output.LayerNorm.weight\n",
      "encoder.layer.10.attention.output.LayerNorm.bias\n",
      "encoder.layer.10.intermediate.dense.weight\n",
      "encoder.layer.10.intermediate.dense.bias\n",
      "encoder.layer.10.output.dense.weight\n",
      "encoder.layer.10.output.dense.bias\n",
      "encoder.layer.10.output.LayerNorm.weight\n",
      "encoder.layer.10.output.LayerNorm.bias\n",
      "encoder.layer.11.attention.self.query.weight\n",
      "encoder.layer.11.attention.self.query.bias\n",
      "encoder.layer.11.attention.self.key.weight\n",
      "encoder.layer.11.attention.self.key.bias\n",
      "encoder.layer.11.attention.self.value.weight\n",
      "encoder.layer.11.attention.self.value.bias\n",
      "encoder.layer.11.attention.output.dense.weight\n",
      "encoder.layer.11.attention.output.dense.bias\n",
      "encoder.layer.11.attention.output.LayerNorm.weight\n",
      "encoder.layer.11.attention.output.LayerNorm.bias\n",
      "encoder.layer.11.intermediate.dense.weight\n",
      "encoder.layer.11.intermediate.dense.bias\n",
      "encoder.layer.11.output.dense.weight\n",
      "encoder.layer.11.output.dense.bias\n",
      "encoder.layer.11.output.LayerNorm.weight\n",
      "encoder.layer.11.output.LayerNorm.bias\n",
      "pooler.dense.weight\n",
      "pooler.dense.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in bert_model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKoR4g4pbZ0y"
   },
   "source": [
    "Now let's turn to BERT's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hqwZzwpmTvfR",
    "outputId": "10013f62-8b9d-4666-a58e-ec417f3392b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.3179,  0.3525,  0.1506,  ..., -0.1706,  0.3517,  0.0125],\n",
       "         [ 0.2948, -0.0997,  0.6395,  ..., -0.0371,  0.2188,  0.3518],\n",
       "         [ 0.1575,  0.6034,  0.7143,  ...,  0.0823,  0.3011,  0.6374],\n",
       "         ...,\n",
       "         [-0.0841,  0.2192,  0.3046,  ..., -0.0895,  0.3235,  0.2655],\n",
       "         [ 0.2485, -0.0316,  0.3258,  ..., -0.1088,  0.4849,  0.0566],\n",
       "         [ 0.2249, -0.0716,  0.2036,  ...,  0.0480,  0.4485,  0.1516]],\n",
       "\n",
       "        [[ 0.3317,  0.3834,  0.0829,  ..., -0.2209,  0.2429, -0.1369],\n",
       "         [ 0.3239, -0.0473,  0.6687,  ..., -0.0043,  0.3423,  0.3567],\n",
       "         [ 0.2500,  0.7461,  0.3597,  ..., -0.1030,  0.2468,  0.7532],\n",
       "         ...,\n",
       "         [ 0.0742,  0.1487,  0.1221,  ..., -0.1052,  0.1900,  0.2008],\n",
       "         [ 0.2734, -0.1222,  0.1121,  ..., -0.0486,  0.4010,  0.1512],\n",
       "         [ 0.2248, -0.0299, -0.0100,  ...,  0.1512,  0.4156,  0.1596]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.6879,  0.4675,  0.9999,  ...,  1.0000, -0.8793,  0.9928],\n",
       "        [-0.5880,  0.5197,  0.9998,  ...,  1.0000, -0.8190,  0.9936]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_output = bert_model(**bert_input)\n",
    "bert_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "davPp5NrUa0s"
   },
   "source": [
    "Let's analyze this a bit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rkPTVxjyTvht",
    "outputId": "283044fc-1720-40d2-ae18-6016c3b3aeca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of first BERT output:  torch.Size([2, 10, 768])\n",
      "Shape of second BERT output:  torch.Size([2, 768])\n"
     ]
    }
   ],
   "source": [
    "print('Shape of first BERT output: ', bert_output[0].shape)\n",
    "print('Shape of second BERT output: ', bert_output[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rz2FwAP7Uq_D"
   },
   "source": [
    "What does that mean? Are the dimensions correct? Why are there 2 outputs? Let's discuss in class. You can (and should!) also go to https://huggingface.co/docs/transformers/model_doc/bert#transformers.TFBertModel and read the documentation. **REALLY(!)**\n",
    " critical.\n",
    "\n",
    "[Return to Top](#returnToTop)  \n",
    "<a id = 'contextualEmbeddings'></a>\n",
    "\n",
    "### 3.3 Context-based Embeddings with BERT\n",
    "\n",
    "We can use this version of the model if we want to access the contextualized embeddings that come from that last hidden layer of the model. The first output of the model provides the full sequence of token embeddings. The second output is basically the CLS token embedding (after one more dense layer transformation).\n",
    "\n",
    "Let's look at the BERT contextualized embeddings for the word \"bank\" when it appears in a few contexts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RuMWhXa8Tvj0",
    "outputId": "97820dca-edaa-4669-ec5b-b02e17cc400a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101,  146, 1444, 1106, 2498, 1139, 1948, 1106, 1103, 3085, 2052,  102,\n",
       "            0],\n",
       "        [ 101,  146, 1209, 1444, 1106, 2498, 1139, 1948, 1106, 1103, 3085, 4911,\n",
       "          102],\n",
       "        [ 101,  146, 1125, 1106, 3085, 1154,  170, 1885,  102,    0,    0,    0,\n",
       "            0],\n",
       "        [ 101, 1109, 3085, 1587, 1200, 1108, 1304, 3505,  102,    0,    0,    0,\n",
       "            0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_bank_inputs = bert_tokenizer([\"I need to bring my money to the bank today\",\n",
    "                                  \"I will need to bring my money to the bank tomorrow\",\n",
    "                                  \"I had to bank into a turn\",\n",
    "                                  \"The bank teller was very nice\" ],\n",
    "                                padding=True,\n",
    "                                return_tensors='pt')\n",
    "\n",
    "bert_bank_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFNpT0-MWFVg"
   },
   "source": [
    "Next, we will get the outputs and extract the word vectors for bank in each of these sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "yqlgKOLVWEcd"
   },
   "outputs": [],
   "source": [
    "bert_bank_outputs = bert_model(**bert_bank_inputs)\n",
    "\n",
    "bank_1 = bert_bank_outputs[0][0, 9]\n",
    "bank_2 = bert_bank_outputs[0][1, 10]\n",
    "bank_3 = bert_bank_outputs[0][2, 4]\n",
    "bank_4 = bert_bank_outputs[0][3, 2]\n",
    "\n",
    "banks = [\n",
    "    bank_1.detach().numpy(),\n",
    "    bank_2.detach().numpy(),\n",
    "    bank_3.detach().numpy(),\n",
    "    bank_4.detach().numpy()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CD0ffO0zWE2y"
   },
   "source": [
    "Where are those numbers coming from?\n",
    "\n",
    "Finally, we obtain the cosine similarities between the 4 vectors (from left to right and top to bottom we iterate through our vectors and report the cosine similarity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q853iPjWV-7-",
    "outputId": "78e342bc-c4e3-43e0-d3ac-7860a333de64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t1.0\t0.99\t0.59\t0.86\n",
      "\t0.99\t1.0\t0.59\t0.87\n",
      "\t0.59\t0.59\t1.0\t0.62\n",
      "\t0.86\t0.87\t0.62\t1.0\n"
     ]
    }
   ],
   "source": [
    "cosine_similarities(banks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LaJkBucTXDpY"
   },
   "source": [
    "Does this look right?\n",
    "\n",
    "[Return to Top](#returnToTop)  \n",
    "<a id = 'BERTClassification'></a>\n",
    "\n",
    "# 4. Text Classification with BERT\n",
    "\n",
    "Now we're ready to load and train our classification model.\n",
    "\n",
    "[Return to Top](#returnToTop)  \n",
    "<a id = 'modelSetup'></a>\n",
    "\n",
    "### 4.1 Classification Model Setup\n",
    "\n",
    "In order to use the BERT model on a new classification task, we'll need a new classification layer on top of the pre-trained transformer layers. Huggingface provides a model class for that purpose, called BertForSequenceClassification.\n",
    "\n",
    "This class will load a model with the full architecture for a new text classification task. It starts with the pre-trained BERT model up until the last hidden layer, then it takes the \"pooler\" output from the BERT model and passes that into a new classification layer of the size we need for our task. (The \"pooler\" output is just the CLS token output, passed through another dense layer, before going to the output layer.)\n",
    "\n",
    "The new classification layer has not been pre-trained, so we'll need to train it for our task. By default, Huggingface will give us an output layer with two classes (which fits our binary classification task), though we can specify a different number of classes if we have a multiclass classification task. We will most likely also want to continue updating the weights of at least some of the pre-trained layers, which we can explore later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1RShlI4_V_JU",
    "outputId": "7d20d202-5f62-4151-bfaa-d90160d45624"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_classification_model = BertForSequenceClassification.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBJISfYHDjh-"
   },
   "source": [
    "This first time through, we'll freeze all of the pre-trained BERT layers to make the fine tuning go much faster. Then later we'll try unfreezing some or all layers and see what works better.\n",
    "\n",
    "We need to keep the final classification layer unfrozen no matter what, because that's a new layer that hasn't been trained at all yet, and needs to be trained for our task.\n",
    "\n",
    "Let's use the named_parameters method to access the names of the weight matrices in the model, and only freeze the pre-trained BERT ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIptlN7ioqNF",
    "outputId": "78a365b6-d3c0-44e9-cf55-6d5f7140cde7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight\n",
      "bert.embeddings.position_embeddings.weight\n",
      "bert.embeddings.token_type_embeddings.weight\n",
      "bert.embeddings.LayerNorm.weight\n",
      "bert.embeddings.LayerNorm.bias\n",
      "bert.encoder.layer.0.attention.self.query.weight\n",
      "bert.encoder.layer.0.attention.self.query.bias\n",
      "bert.encoder.layer.0.attention.self.key.weight\n",
      "bert.encoder.layer.0.attention.self.key.bias\n",
      "bert.encoder.layer.0.attention.self.value.weight\n",
      "bert.encoder.layer.0.attention.self.value.bias\n",
      "bert.encoder.layer.0.attention.output.dense.weight\n",
      "bert.encoder.layer.0.attention.output.dense.bias\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.0.intermediate.dense.weight\n",
      "bert.encoder.layer.0.intermediate.dense.bias\n",
      "bert.encoder.layer.0.output.dense.weight\n",
      "bert.encoder.layer.0.output.dense.bias\n",
      "bert.encoder.layer.0.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.attention.self.query.weight\n",
      "bert.encoder.layer.1.attention.self.query.bias\n",
      "bert.encoder.layer.1.attention.self.key.weight\n",
      "bert.encoder.layer.1.attention.self.key.bias\n",
      "bert.encoder.layer.1.attention.self.value.weight\n",
      "bert.encoder.layer.1.attention.self.value.bias\n",
      "bert.encoder.layer.1.attention.output.dense.weight\n",
      "bert.encoder.layer.1.attention.output.dense.bias\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.intermediate.dense.weight\n",
      "bert.encoder.layer.1.intermediate.dense.bias\n",
      "bert.encoder.layer.1.output.dense.weight\n",
      "bert.encoder.layer.1.output.dense.bias\n",
      "bert.encoder.layer.1.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.attention.self.query.weight\n",
      "bert.encoder.layer.2.attention.self.query.bias\n",
      "bert.encoder.layer.2.attention.self.key.weight\n",
      "bert.encoder.layer.2.attention.self.key.bias\n",
      "bert.encoder.layer.2.attention.self.value.weight\n",
      "bert.encoder.layer.2.attention.self.value.bias\n",
      "bert.encoder.layer.2.attention.output.dense.weight\n",
      "bert.encoder.layer.2.attention.output.dense.bias\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.intermediate.dense.weight\n",
      "bert.encoder.layer.2.intermediate.dense.bias\n",
      "bert.encoder.layer.2.output.dense.weight\n",
      "bert.encoder.layer.2.output.dense.bias\n",
      "bert.encoder.layer.2.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.attention.self.query.weight\n",
      "bert.encoder.layer.3.attention.self.query.bias\n",
      "bert.encoder.layer.3.attention.self.key.weight\n",
      "bert.encoder.layer.3.attention.self.key.bias\n",
      "bert.encoder.layer.3.attention.self.value.weight\n",
      "bert.encoder.layer.3.attention.self.value.bias\n",
      "bert.encoder.layer.3.attention.output.dense.weight\n",
      "bert.encoder.layer.3.attention.output.dense.bias\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.intermediate.dense.weight\n",
      "bert.encoder.layer.3.intermediate.dense.bias\n",
      "bert.encoder.layer.3.output.dense.weight\n",
      "bert.encoder.layer.3.output.dense.bias\n",
      "bert.encoder.layer.3.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.attention.self.query.weight\n",
      "bert.encoder.layer.4.attention.self.query.bias\n",
      "bert.encoder.layer.4.attention.self.key.weight\n",
      "bert.encoder.layer.4.attention.self.key.bias\n",
      "bert.encoder.layer.4.attention.self.value.weight\n",
      "bert.encoder.layer.4.attention.self.value.bias\n",
      "bert.encoder.layer.4.attention.output.dense.weight\n",
      "bert.encoder.layer.4.attention.output.dense.bias\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.intermediate.dense.weight\n",
      "bert.encoder.layer.4.intermediate.dense.bias\n",
      "bert.encoder.layer.4.output.dense.weight\n",
      "bert.encoder.layer.4.output.dense.bias\n",
      "bert.encoder.layer.4.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.attention.self.query.weight\n",
      "bert.encoder.layer.5.attention.self.query.bias\n",
      "bert.encoder.layer.5.attention.self.key.weight\n",
      "bert.encoder.layer.5.attention.self.key.bias\n",
      "bert.encoder.layer.5.attention.self.value.weight\n",
      "bert.encoder.layer.5.attention.self.value.bias\n",
      "bert.encoder.layer.5.attention.output.dense.weight\n",
      "bert.encoder.layer.5.attention.output.dense.bias\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.intermediate.dense.weight\n",
      "bert.encoder.layer.5.intermediate.dense.bias\n",
      "bert.encoder.layer.5.output.dense.weight\n",
      "bert.encoder.layer.5.output.dense.bias\n",
      "bert.encoder.layer.5.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.attention.self.query.weight\n",
      "bert.encoder.layer.6.attention.self.query.bias\n",
      "bert.encoder.layer.6.attention.self.key.weight\n",
      "bert.encoder.layer.6.attention.self.key.bias\n",
      "bert.encoder.layer.6.attention.self.value.weight\n",
      "bert.encoder.layer.6.attention.self.value.bias\n",
      "bert.encoder.layer.6.attention.output.dense.weight\n",
      "bert.encoder.layer.6.attention.output.dense.bias\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.intermediate.dense.weight\n",
      "bert.encoder.layer.6.intermediate.dense.bias\n",
      "bert.encoder.layer.6.output.dense.weight\n",
      "bert.encoder.layer.6.output.dense.bias\n",
      "bert.encoder.layer.6.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.attention.self.query.weight\n",
      "bert.encoder.layer.7.attention.self.query.bias\n",
      "bert.encoder.layer.7.attention.self.key.weight\n",
      "bert.encoder.layer.7.attention.self.key.bias\n",
      "bert.encoder.layer.7.attention.self.value.weight\n",
      "bert.encoder.layer.7.attention.self.value.bias\n",
      "bert.encoder.layer.7.attention.output.dense.weight\n",
      "bert.encoder.layer.7.attention.output.dense.bias\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.intermediate.dense.weight\n",
      "bert.encoder.layer.7.intermediate.dense.bias\n",
      "bert.encoder.layer.7.output.dense.weight\n",
      "bert.encoder.layer.7.output.dense.bias\n",
      "bert.encoder.layer.7.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.attention.self.query.weight\n",
      "bert.encoder.layer.8.attention.self.query.bias\n",
      "bert.encoder.layer.8.attention.self.key.weight\n",
      "bert.encoder.layer.8.attention.self.key.bias\n",
      "bert.encoder.layer.8.attention.self.value.weight\n",
      "bert.encoder.layer.8.attention.self.value.bias\n",
      "bert.encoder.layer.8.attention.output.dense.weight\n",
      "bert.encoder.layer.8.attention.output.dense.bias\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.intermediate.dense.weight\n",
      "bert.encoder.layer.8.intermediate.dense.bias\n",
      "bert.encoder.layer.8.output.dense.weight\n",
      "bert.encoder.layer.8.output.dense.bias\n",
      "bert.encoder.layer.8.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.attention.self.query.weight\n",
      "bert.encoder.layer.9.attention.self.query.bias\n",
      "bert.encoder.layer.9.attention.self.key.weight\n",
      "bert.encoder.layer.9.attention.self.key.bias\n",
      "bert.encoder.layer.9.attention.self.value.weight\n",
      "bert.encoder.layer.9.attention.self.value.bias\n",
      "bert.encoder.layer.9.attention.output.dense.weight\n",
      "bert.encoder.layer.9.attention.output.dense.bias\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.intermediate.dense.weight\n",
      "bert.encoder.layer.9.intermediate.dense.bias\n",
      "bert.encoder.layer.9.output.dense.weight\n",
      "bert.encoder.layer.9.output.dense.bias\n",
      "bert.encoder.layer.9.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.attention.self.query.weight\n",
      "bert.encoder.layer.10.attention.self.query.bias\n",
      "bert.encoder.layer.10.attention.self.key.weight\n",
      "bert.encoder.layer.10.attention.self.key.bias\n",
      "bert.encoder.layer.10.attention.self.value.weight\n",
      "bert.encoder.layer.10.attention.self.value.bias\n",
      "bert.encoder.layer.10.attention.output.dense.weight\n",
      "bert.encoder.layer.10.attention.output.dense.bias\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.intermediate.dense.weight\n",
      "bert.encoder.layer.10.intermediate.dense.bias\n",
      "bert.encoder.layer.10.output.dense.weight\n",
      "bert.encoder.layer.10.output.dense.bias\n",
      "bert.encoder.layer.10.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.attention.self.query.weight\n",
      "bert.encoder.layer.11.attention.self.query.bias\n",
      "bert.encoder.layer.11.attention.self.key.weight\n",
      "bert.encoder.layer.11.attention.self.key.bias\n",
      "bert.encoder.layer.11.attention.self.value.weight\n",
      "bert.encoder.layer.11.attention.self.value.bias\n",
      "bert.encoder.layer.11.attention.output.dense.weight\n",
      "bert.encoder.layer.11.attention.output.dense.bias\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.intermediate.dense.weight\n",
      "bert.encoder.layer.11.intermediate.dense.bias\n",
      "bert.encoder.layer.11.output.dense.weight\n",
      "bert.encoder.layer.11.output.dense.bias\n",
      "bert.encoder.layer.11.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.output.LayerNorm.bias\n",
      "bert.pooler.dense.weight\n",
      "bert.pooler.dense.bias\n",
      "classifier.weight\n",
      "classifier.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in bert_classification_model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "PbFsTmdPuYx6"
   },
   "outputs": [],
   "source": [
    "for name, param in bert_classification_model.named_parameters():\n",
    "    if name.split(\".\")[0] == \"bert\":\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2tk0Cs2GnoJZ",
    "outputId": "2a1a654e-42c9-46c1-9fca-f6fe9a70fd90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "BertForSequenceClassification                                --\n",
       "├─BertModel: 1-1                                             --\n",
       "│    └─BertEmbeddings: 2-1                                   --\n",
       "│    │    └─Embedding: 3-1                                   (22,268,928)\n",
       "│    │    └─Embedding: 3-2                                   (393,216)\n",
       "│    │    └─Embedding: 3-3                                   (1,536)\n",
       "│    │    └─LayerNorm: 3-4                                   (1,536)\n",
       "│    │    └─Dropout: 3-5                                     --\n",
       "│    └─BertEncoder: 2-2                                      --\n",
       "│    │    └─ModuleList: 3-6                                  (85,054,464)\n",
       "│    └─BertPooler: 2-3                                       --\n",
       "│    │    └─Linear: 3-7                                      (590,592)\n",
       "│    │    └─Tanh: 3-8                                        --\n",
       "├─Dropout: 1-2                                               --\n",
       "├─Linear: 1-3                                                1,538\n",
       "=====================================================================================\n",
       "Total params: 108,311,810\n",
       "Trainable params: 1,538\n",
       "Non-trainable params: 108,310,272\n",
       "====================================================================================="
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm all pre-trained layers are frozen\n",
    "summary(bert_classification_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsII_FO6pdvg"
   },
   "source": [
    "[Return to Top](#returnToTop)  \n",
    "<a id = 'modelTraining'></a>\n",
    "\n",
    "### 4.2 Model Training\n",
    "\n",
    "To train a Huggingface model, we'll use a Trainer class, and a TrainingArguments class that goes with it.\n",
    "\n",
    "Let's start with the TrainingArguments. This is just a simple config where we specify things like the batch size and number of epochs.\n",
    "\n",
    "We also choose a filepath where we want to save model checkpoints after training. For now, we'll just define a local directory name, which will save the trained model in the Colab notebook's temporary storage.\n",
    "\n",
    "For your assignments and project, you'll probably want to mount your Google Drive and specify a filepath to a directory there, so that the saved model checkpoints persist after the notebook is shut down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "75LvcNhFpoM_"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_epochs = 1\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"bert_fine_tuned_imdb\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to='none'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjlCsBX3r1BZ"
   },
   "source": [
    "In addition to model loss, we'll also want to keep track of a simple but more interpretable metric like validation accuracy, so that we can see how well the model is generalizing.\n",
    "\n",
    "The trainer takes a \"compute_metrics\" argument, which needs to be a function that takes a set of predictions and labels and returns a metric. We can use the accuracy metric from the Huggingface evaluate package, and wrap it in the necessary function like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "35363aaf030847bf84bfdf3d02e54596",
      "93c2623dd76543469404018839ef3ac2",
      "eccc1c1b627c4d55a61e93a4e0a31eb9",
      "74a8ef8b6afc40f7927b3cda95bce430",
      "c1cf058a07594dde92237c26c09fa07e",
      "a7da448b65574f88a2769d958dd5e4e4",
      "67db540493bf4d298b3b8b92d3f96ed7",
      "7b5dc29ec6444421be94c593ee29a411",
      "a8a6e26809fb436f9264d874947a04b7",
      "66fc01a6410d4361a4013b7cecfacbff",
      "f96f0eddc41d44f0bf7fec3ccd73354a"
     ]
    },
    "id": "JDSKeFugr1Jp",
    "outputId": "cf6f960f-b354-4965-ed0e-8da9b2bd2663"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35363aaf030847bf84bfdf3d02e54596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = evaluate.load('accuracy')\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYbWrBLArpap"
   },
   "source": [
    "Now we make our Trainer, passing it the model to use, the training arguments, the training and validation data, and our compute_metrics function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "pt9QuUSPrpjN"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=bert_classification_model,\n",
    "    args=training_args,\n",
    "    train_dataset=imdb_train_dataset,\n",
    "    eval_dataset=imdb_dev_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KVxfWejquYx6"
   },
   "source": [
    "... and train it!  (This takes a few minutes; we might only be able to train for one epoch in the live session.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "xTQnDuypuYyD",
    "outputId": "f8a4b055-6512-4b64-ddfb-721aa570a809"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 00:39, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.689605</td>\n",
       "      <td>0.518000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=313, training_loss=0.7032082164630341, metrics={'train_runtime': 40.2722, 'train_samples_per_second': 124.155, 'train_steps_per_second': 7.772, 'total_flos': 328888819200000.0, 'train_loss': 0.7032082164630341, 'epoch': 1.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbbrP-Tk4752"
   },
   "source": [
    "How well does it work? Can we do better? In the code above, we trained the extra hidden and classification layers that we added on top of BERT for our task. But we froze the BERT model (set trainable=False) so we're leaving the pre-trained BERT layers as-is and only our dense layer is learning.\n",
    "\n",
    "[Return to Top](#returnToTop)  \n",
    "<a id = 'classExercise'></a>\n",
    "\n",
    "### 4.3 Class Exercise\n",
    "\n",
    "Why didn't that work very well? Most likely it's because we froze all of the pre-trained layers. The way we use BERT for classification tasks, we're relying on the CLS token (and the pooler dense layer after it). Those were pre-trained using the next sentence prediction task (they don't really get trained in the masked language model task, because there's no real token there to mask).\n",
    "\n",
    "People have generally found the next sentence prediction task to not be very useful pretraining for downstream tasks. The architecture is good, but we almost always need to fine-tune at least some of the transformer layers, to teach the CLS token how to capture useful context from the rest of the text (the real tokens) for a classification task.\n",
    "\n",
    "Let's try unfreezing only the topmost transformer block and pooler layer (as well as the classification layer, always), or leaving all of the layers in the entire model unfrozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "PZjhLV4XoEU9",
    "outputId": "ce812a21-5412-4270-8f0e-42802edd1e95"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 00:50, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.386369</td>\n",
       "      <td>0.808000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=313, training_loss=0.5156440612987969, metrics={'train_runtime': 50.324, 'train_samples_per_second': 99.356, 'train_steps_per_second': 6.22, 'total_flos': 328888819200000.0, 'train_loss': 0.5156440612987969, 'epoch': 1.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's get a fresh instance of the bert_model -- good practice\n",
    "bert_classification_model = BertForSequenceClassification.from_pretrained(checkpoint)\n",
    "\n",
    "#freeze all layers except the last transformer block (\"layer.11\", the pooler layer and the classification layer)\n",
    "for name, param in bert_classification_model.named_parameters():\n",
    "    if not any(x in name for x in [\"layer.11\", \"bert.pooler\", \"classifier\"]):\n",
    "        param.requires_grad = False\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=bert_classification_model,\n",
    "    args=training_args,\n",
    "    train_dataset=imdb_train_dataset,\n",
    "    eval_dataset=imdb_dev_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xp5rgAQRF9ii"
   },
   "source": [
    "Now let's allow all of the layers to be modified as part of fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "eWaiu0ZAtxF8",
    "outputId": "6df0ff79-77b0-4c0f-8324-17e37ddc4126"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [313/313 02:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.346721</td>\n",
       "      <td>0.858000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=313, training_loss=0.44326504350851137, metrics={'train_runtime': 129.385, 'train_samples_per_second': 38.644, 'train_steps_per_second': 2.419, 'total_flos': 328888819200000.0, 'train_loss': 0.44326504350851137, 'epoch': 1.0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's get a fresh instance of the bert_model -- good practice\n",
    "bert_classification_model = BertForSequenceClassification.from_pretrained(checkpoint)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=bert_classification_model,\n",
    "    args=training_args,\n",
    "    train_dataset=imdb_train_dataset,\n",
    "    eval_dataset=imdb_dev_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94XZuvsJJbs-"
   },
   "source": [
    "What do you think? You'll explore these options more on your own in Assignment 2."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
