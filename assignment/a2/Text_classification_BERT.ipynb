{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7BzBd-N9mS1"
      },
      "source": [
        "# Assignment 2: Text Classification with BERT\n",
        "\n",
        "**Description:** This assignment notebook builds on the material from the\n",
        "[lesson 4 notebook](https://github.com/datasci-w266/2025-fall-main/blob/master/materials/lesson_notebooks/lesson_4_BERT.ipynb), in which we fine-tuned a BERT model for the IMDB movie reviews sentiment classification task. In that notebook, we used the bert-base-cased model and applied traditional fine-tuning, with a brief class exercise at the end to try unfreezing different numbers of layers. In this assignment, we'll start with that exercise, and ask you to explore unfreezing more specific layers yourself. Then you'll search for and try different pre-trained BERT-style models.\n",
        "\n",
        "This notebook should be run on a Google Colab leveraging a GPU. By default, when you open the notebook in Colab it will try to use a GPU. Please note that you the GPU is reuqired for Section 3 but not for Sections 1 and 2.\n",
        "Since colab is providing free access to a GPU they place constraints on that access.  Therefore you might want to turn off the GPU access (Edit -> Notebook Settings) until you get to section 3.  Total runtime of the entire notebook (with solutions and a Colab GPU) should be about 1h with the majority of that time being in Section 3. If Colab tells you that you have reached your GPU limit, wait up to 24 hours and you should be able to access a GPU again.\n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/datasci-w266/2025-fall-main/blob/master/assignment/a2/Text_classification_BERT.ipynb)\n",
        "\n",
        "The overall assignment structure is as follows:\n",
        "\n",
        "\n",
        "0. Setup\n",
        "  \n",
        "  0.1 Libraries and Helper Functions\n",
        "\n",
        "  0.2 Data Acquisition\n",
        "\n",
        "  0.3. Data Preparation\n",
        "\n",
        "\n",
        "1. Classification with BERT\n",
        "\n",
        "  1.1. BERT Basics\n",
        "\n",
        "  1.2 CLS-Token-based Classification\n",
        "\n",
        "  1.3 Averaging of BERT Outputs\n",
        "\n",
        "  1.4. Adding a CNN on top of BERT\n",
        "\n",
        "\n",
        "\n",
        "**INSTRUCTIONS:**:\n",
        "\n",
        "* Questions are always indicated as **QUESTION**, so you can search for this string to make sure you answered all of the questions. You are expected to fill out, run, and submit this notebook, as well as to answer the questions in the **answers** file as you did in a1.  Please do **not** remove the output from your notebooks when you submit them as we'll look at the output as well as your code for grading purposes.  We cannot award points if the output cells are empty.\n",
        "\n",
        "* **### YOUR CODE HERE** indicates that you are supposed to write code.\n",
        "\n",
        "* If you want to, you can run all of the cells in section 0 in bulk. This is setup work and no questions are in there. At the end of section 0 we will state all of the relevant variables that were defined and created in section 1.\n",
        "\n",
        "* Finally, unless otherwise indicated your validation accuracy will be 0.65 or higher if you have correctly implemented the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so-yur1S9mS4"
      },
      "source": [
        "## 0. Setup\n",
        "\n",
        "### 0.1. Libraries and Helper Functions\n",
        "\n",
        "This notebook requires the Hugging Face datasets and other prerequisites that you must download.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uQnMctL9mS5",
        "outputId": "6b1a75e7-7431-44e5-eabe-8b5ee246f192"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q torchinfo\n",
        "!pip install -U -q datasets fsspec huggingface_hub # Hugging Face's dataset library\n",
        "!pip install -q evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFFBvPMR9mS8"
      },
      "source": [
        "Now we are ready to do the imports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q8b9aykE9mS8"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import transformers\n",
        "import evaluate\n",
        "\n",
        "from datasets import load_dataset\n",
        "from torchinfo import summary\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIL1eUtV9mTC"
      },
      "source": [
        "### 0.2 Data Acquisition\n",
        "\n",
        "\n",
        "We will use the IMDB dataset delivered as part of the TensorFlow-datasets library, and split into training and test sets. For expedience, we will limit ourselves in terms of train and test examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350,
          "referenced_widgets": [
            "ce8f54be606749d89eeafe7ca00ef041",
            "0b1f02e31b4a4f678a0287779eec6b1f",
            "79d24979324e49068cd5836237c9af01",
            "e0947a14884048438b271d87781dd900",
            "59095767deee4bf08543780af51f9934",
            "05fd34491a2e4794b4621ca43c265fd3",
            "c4807def67fb4aba857e54b2c52ffd9a",
            "8afc429470c54c9aa1c561d12c66a48d",
            "f792758483a742feb5374f0937a86784",
            "68efaac86e3643beb1ab4b38a0c8d703",
            "33da647d14eb4efd9918cf1015d7f761",
            "f6c0b60a66cb4bb29db0d622615c2bfc",
            "3e57b93259744db0929f198ff32296dd",
            "3e47dad30e404868b7ed1751b900fe84",
            "092ac5f85df54adb899b2f78ad204947",
            "e21a05ba103d4477834aeca452f29f75",
            "73f6e8389ebc4bc1af58a4ee48b9e8cc",
            "7dab03fa06cb48219108c6674377bcdb",
            "52764fcf8a574e67aaae8e11be5a1797",
            "28a0c3deb7a941978df2c890dcb96312",
            "afdec16b2a8c49fbb7e3a0453abee344",
            "b4299a0ac09e4df08a39989c537d811e",
            "462e79f1b27d4732b0975e77821e2d53",
            "f9d38ad07e904242a1fe807b7428842b",
            "b3646b2d73f34f4cb56301858e409838",
            "247f5ba3c78541e69a4cac38c1b9555b",
            "e209e98e4ef542e59666746d5d9e72c8",
            "a9c01f4fc1a94aa5a82480469b5c2092",
            "caafc83b2d384f849cb57c23e6bdda07",
            "bd0e3ccdcb0f4ac39c8325cb65876f65",
            "9555536213b54864b6d8defd5ccaf337",
            "b580cf12d23b487e9639d25d2e65831f",
            "02017609f07a4fb3b129d95df38f7489",
            "7bd11ebbee1840e693dcb0eeb2b4f236",
            "cd4ca8f4e1b94f809eff1e2a07b67f81",
            "a5bc923dd50e4d0a902d684fad7ca1ea",
            "df64abb9995b41148b59fb8929a2ac19",
            "675739c21298456c96c5cafbda244192",
            "693e0dad4f1d43868afd417ed8b6e004",
            "a77d35de94fc4fd4956a5a85e0a5ef52",
            "d806d73072b94967ab29daa382d8b99e",
            "e48b161573bd484aa907a3050210cf92",
            "eb45c91c1c204ba993dc0f38fb1357c5",
            "28e855cf0e924b79adf4516015b9dcd3",
            "24676938bc10479583a4fbfafe47383e",
            "ae948ae7e26541e1b0dbcb5a4a4908a5",
            "5b2fd7c00af74ba298a0517c8a0796a8",
            "d96863afcf1f411f8592d79b3d24579e",
            "c18b66b7d8a94edc9059408f104c8b9c",
            "a914d7a8634a4f22a45b0e75e92e6ca5",
            "2ab88616cf4745d5b7d8c366a8abea67",
            "db55f9e1ac974f25a62c3e2cdc0a23d5",
            "061da7855f144ef2a1835eb60aed29c2",
            "5bac4118968d405da0906c7e62a92733",
            "d7247ce821684b8aafea19a5f10a1f7f",
            "e97ff8db045f409892dfe2ed21c1de48",
            "36908ec5f6d74b07853618aa4baf317b",
            "80bfe692943d4f46a4397fdbd6dbb766",
            "3fbc0d677b1344e3b2a8ef0f28e32c02",
            "942c87db79c243d1a6d82a664ed44064",
            "19c1797d273545e691dd1ab3fe5d2581",
            "1d5715498e8244d2b9969b88d8936451",
            "f911c7194a0b42719957e4e3257d37cd",
            "b39dec729aad40f68db23ba11e7fba4b",
            "70d11c76a8f8442999ff51b129ef760f",
            "191914f8970540fcad31eb9c03e12be0",
            "cd624f93888e40a1bb539e55b6237fc6",
            "9cca3e16329f4eb199b9df7d3b0018c2",
            "54967d8d95be4a0b8f8a5306e2c63213",
            "10bd77cfd67e4f3386957ac455a0c5cd",
            "6f038803f3dd41fe8b20509ddc96030f",
            "3726f16a40b14ceabc3644eaf532b7ad",
            "94054a5bf66948f89546ae546dd7fc98",
            "de709432a3d34af89824a25cffcd3501",
            "aaa29b9e430449c9a30d18655e11546b",
            "38875eec2326454cb1157c651e9ff433",
            "ae97e73909284d76a91fa7d1a87a3226"
          ]
        },
        "id": "uwOF0qYb9mTC",
        "outputId": "4d30da64-57fe-4588-aff0-8cdd521428a7"
      },
      "outputs": [],
      "source": [
        "imdb_dataset = load_dataset(\"imdb\")\n",
        "\n",
        "imdb_train_dataset = imdb_dataset['train'].shuffle()\n",
        "imdb_dev_dataset = imdb_dataset['test'].shuffle().select(range(5000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPHFtgGkHNOQ"
      },
      "source": [
        "It is always highly recommended to look at the data. What do the records look like? Are they clean or do they contain a lot of cruft (potential noise)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvmWKdVQ9mTC",
        "outputId": "bad3d9de-046b-4af2-976d-51407a2923e8"
      },
      "outputs": [],
      "source": [
        "imdb_train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzEnCspD9mTD",
        "outputId": "940b7e1e-93a5-4a6e-b53f-9ffa143e09d1"
      },
      "outputs": [],
      "source": [
        "for i in range(4):\n",
        "  print(imdb_train_dataset['text'][i])\n",
        "  print(imdb_train_dataset['label'][i])\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94gU6o4H-vtB",
        "outputId": "ddfcfbf5-5ae1-4893-924c-a01d2fbb6fc5"
      },
      "outputs": [],
      "source": [
        "imdb_train_dataset.features['label'].names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CplHsqSDMKCa"
      },
      "source": [
        "For convenience, in this assignment we will define a sequence length and truncate all records at that length. For records that are shorter than our defined sequence length we will add padding characters to insure that our input shapes are consistent across all records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Zxu9U3qXMKTW"
      },
      "outputs": [],
      "source": [
        "MAX_SEQUENCE_LENGTH = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bHwj4vu9mTD"
      },
      "source": [
        "## 0.3. Data Preparation\n",
        "\n",
        "We will need to tokenize the text into vocab_ids to pass into a BERT model. To do so, we'll need to use the specific tokenizer that goes with the model we're using. In this notebook, we will try several different BERT-style models. Let's\n",
        "first write a function that will take the text from our dataset and a tokenizer, and encode the text using that tokenizer. Then we'll apply the function to our dataset for each tokenizer and model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "G1wstKkJBVeb"
      },
      "outputs": [],
      "source": [
        "def preprocess_imdb(data, tokenizer):\n",
        "    review_text = data['text']\n",
        "\n",
        "    encoded = tokenizer.batch_encode_plus(\n",
        "            review_text,\n",
        "            max_length=MAX_SEQUENCE_LENGTH,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_token_type_ids=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "    return encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BGRT1g6a0T6"
      },
      "source": [
        "\n",
        "## 1. BERT-based Classification Models\n",
        "\n",
        "Now we turn to classification with BERT. We will perform classifications with various models that are based on pre-trained BERT models.  If you turn off GPU access while coding and debugging the setup steps, make sure you change the Notebook settings so you can access a GPU when you're ready to train the models.\n",
        "\n",
        "\n",
        "### 1.1. Basics\n",
        "\n",
        "Let us first explore some basics of BERT. We'll start by loading the first pretrained BERT model and tokenizer that we'll use ('bert-base-cased').\n",
        "\n",
        "To explore just the pre-trained portion of the model, we'll use the AutoModel class (equivalent to BertModel, but works for any architecture including BERT). This class gives us the pre-trained model layers up until the last hidden layer (but not any output layer)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "a9090e8b05594243b00bc5a9ffe6550c",
            "0e2aaccd145b485ba577cdc28d3c5d02",
            "8695f30bd55149e6bc41314ee75ce9a9",
            "16b350191bb1410abacd3eb3b6efa101",
            "89216b93f3a94f8c9a341c1995efdd13",
            "32a4dcca02694a5fa5b1e4217e8be39c",
            "5da44a06046c428eb4228786cf9dbbb8",
            "b2ac3fd0eec648789244b207e59a75a4",
            "a0a043f41b2349e58aa43a68efe17416",
            "20311f25af9b496ab65561d8b0bca613",
            "0d153848b87840e6bc6147f4bf6a2bb7",
            "50e9a4ed1b8b4d8f8742d51adc278554",
            "13dd9c0d10a04547ad5c1aa5978ddd0b",
            "bc2a5d2030a94900a878d9975f398adc",
            "35a2f2b323714672affe8bd010930a0d",
            "ab1019298b79490c8f246dc162e7af6a",
            "6d12e41ee0aa4d0aa43bd57969dc5d5b",
            "f0ee6e62d5b54e7c8262cb44c6d62c4b",
            "89c4158f603f4480b24fb0a113d8e242",
            "def3d3ef8dbe4379b1a713ecd632331a",
            "0d9dae30390d40c0a13ce4bece6ac49e",
            "8977c4e192cf4ed5b18fe17491c38a8d",
            "afbec7b612764ef2917a13c4937c2d05",
            "870eeecc7c0748739287a92afcf859da",
            "84e16b29ba5f4366852340c9634e594f",
            "848182fbcff54aaf9b88f0df1912291a",
            "1c02b70e70354d02b9ac2a667da9f4bc",
            "c826044f163147918879bc501360f743",
            "8bdd95638f2f4e00b18fdb6de731ac41",
            "d51b00cdb05c4630acb46271d490fd9e",
            "b52162c7b89d483aae861e5cb18fbce2",
            "2855def2c55a41c4b1b35d3eac53b420",
            "06f0d62adec24976925a3bf15d2d78a8",
            "302b5c563c1a4b11b72d4e7b25dfc391",
            "c3a41604df1f4a1083a02754abf0a0e2",
            "ea55fbb7b5b94af581493de91e873260",
            "f99ae3cc17d948f9b9b4e1e9338d6d06",
            "1038f273e9b24151afefeb89e9af882a",
            "b680e88c37af4e63a252066a3221f939",
            "2dd4cccddebd4cdbaf45b87f2434eac9",
            "c8dd4930a21d4304abbab6037d470955",
            "3c94738ddf8b45c4854cde2fb1a5b8c5",
            "c37f90d91ea94a48a46d1c89814e9a17",
            "8d9e37e86e58497f8fde86f15ad394dc",
            "10211ed3ec1948599b0d205dc2f51a55",
            "c04bdeafad8f40d88bc833e230d81081",
            "c9989e29ace944a6a38dc852912593e6",
            "fb0f344b1c254d9cb7829f8a605e6c56",
            "30d7753c1b9d4dd694f6cc7b2df3132f",
            "3a096436677f4ca68968a2c4dec7fb05",
            "cf2af0f160a94ba486e04d89b8fce46a",
            "f5acab2f7cc24087ae7f90797836e74e",
            "f58a80a9de06453ca8fa726620793c5b",
            "7ca5573c176f4dc09cf0e8e5c955c563",
            "4e3fb0660b874c2986ddec760dcf6e21"
          ]
        },
        "id": "dj9IybD-BtWk",
        "outputId": "fc6781ae-6ed7-4f34-dfc2-6b97948e5278"
      },
      "outputs": [],
      "source": [
        "bert_tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "bert_model = AutoModel.from_pretrained('bert-base-cased')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU-H_JP7K8Tj"
      },
      "source": [
        "Let's look at a couple of example sentences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aM3UggLagPn4"
      },
      "outputs": [],
      "source": [
        "test_input = ['this bank is closed on Sunday', 'the steepest bank of the river is dangerous']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWaNDy5UbmGU"
      },
      "source": [
        "Apply the BERT tokenizer to tokenize them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmoptRz0bq1o",
        "outputId": "513eb5be-126c-4d12-b1dd-58493ad87b06"
      },
      "outputs": [],
      "source": [
        "tokenized_input = bert_tokenizer(test_input,\n",
        "                                 max_length=12,\n",
        "                                 truncation=True,\n",
        "                                 padding='max_length',\n",
        "                                 return_tensors='pt')\n",
        "\n",
        "tokenized_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8WYd810dQwh"
      },
      "source": [
        " **QUESTION:**\n",
        "\n",
        " 1.a  Why do the attention_masks have 4 and 1 zeros, respectively?  Choose the correct one and enter it in the answers file.\n",
        "\n",
        "  *  For the first example the last four tokens belong to a different segment. For the second one it is only the last token.\n",
        "\n",
        "  *  For the first example 4 positions are padded while for the second one it is only one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4hpNQPvBehMc"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "# bert_output = ...\n",
        "\n",
        "\n",
        "### END YOUR CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVNsqd6QRepy"
      },
      "source": [
        " **QUESTION:**\n",
        "\n",
        " 1.b How many outputs are there?\n",
        "\n",
        " Enter your code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAfOnO9zov-y",
        "outputId": "dfad64e3-6088-4588-efd3-9f5d857fdddf"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "#b. -> print it out\n",
        "\n",
        "\n",
        "\n",
        "### END YOUR CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYM-7tMItaal"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "1.c Which output do we need to use to get token-level embeddings?\n",
        "\n",
        "the first\n",
        "\n",
        "the second\n",
        "\n",
        "Put your answer in the answers file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EYXhams6Bs6"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        " 1.d In the tokenized input, which input_id number (i.e. the vocabulary id) corresponds to 'bank' in the two sentences? ('bert_tokenizer.tokenize()' may come in handy.. and don't forget the CLS token! )\n",
        "\n",
        "\n",
        "**QUESTION:**\n",
        "\n",
        " 1.e In the array of tokens, which position index number corresponds to 'bank' in the first sentence? ('bert_tokenizer.tokenize()' may come in handy.. and don't forget the CLS token! )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X-bPMr56Bs6",
        "outputId": "fc7ead25-d7df-4650-9d0d-95c3842b212f"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "#d/e. -> Look at tokens generated by the bert tokenizer for the first example\n",
        "\n",
        "\n",
        "### END YOUR CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmC3H1-96Bs6"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "1.f Which array position index number corresponds to 'bank' in the second sentence?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiJrrKo26Bs6",
        "outputId": "77b445c2-d766-4320-bac7-ccccdeeef225"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "#f. -> Look at tokenization for the second example\n",
        "\n",
        "\n",
        "### END YOUR CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd-Q-3MA6Bs6"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        " 1.g What is the cosine similarity between the BERT embeddings for the two occurences of 'bank' in the two sentences?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVIt83S26Bs6",
        "outputId": "81544ee8-95cc-462b-9891-97c693907912"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "#g.  -> get the vectors and calculate cosine similarity between the two 'bank' BERT embedddings\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### END YOUR CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a2zCWHP6Bs6"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "1.h How does this relate to the cosine similarity of 'this' (in sentence 1) and the first 'the' (in sentence 2). Compute their cosine similarity.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnEWs6St6Bs6",
        "outputId": "6043dffd-ba56-4d5a-ca74-71b216a77ae7"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE\n",
        "\n",
        "#h.  -> get the vectors and calculate cosine similarity\n",
        "\n",
        "\n",
        "### END YOUR CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBOvsTBwm_Vi"
      },
      "source": [
        "### 2. Testing Different Pre-Trained BERT Models\n",
        "\n",
        "In the live session we discussed classification with the `bert-base-cased` model, using the Huggingface class BertForSequenceClassification, which comes with a new output layer for our task that we need to train on our dataset.\n",
        "\n",
        "We're going to try different pre-trained models now. Like in the lesson 4 notebook, we'll want to fine-tune each model on our IMDB reviews dataset and compare them with a metric like the validation accuracy. We'll use the model class AutoModelForSequenceClassification, which is equivalent to BertForSequenceClassification, but works for other similar architectures too.\n",
        "\n",
        "Let's write the code we'll need as a function that takes the model and tokenizer as arguments, along with the raw train and dev data. The function will need to tokenize the inputs using the provided tokenizer, so that we can repeat the same code for different pre-trained models. Then the function should create the training args and trainer class, and call trainer.train().\n",
        "\n",
        "The other hyperparameters you'll need are provided in the function definition, including batch_size and num_epochs. You should use the default values provided for those. Use the function provided below for compute_metrics.\n",
        "\n",
        "For now, keep all layers of the pre-trained models you load unfrozen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ad94a3bbf1ca481895b7f79f3007a031",
            "383f01f3603d41cda40af4bf82ecc2e0",
            "ca02ae7709af422fa3f541c61851d7e9",
            "b709c9e507eb47e58c9d14d6cb1c20cf",
            "89084d6fdfa84fe088badab522c233ec",
            "a3afcdf16591429dab7fb353d89e8831",
            "b4bb8719936f4f8585641bee7b19484a",
            "98d92159122849e8bf6c510b46bd121f",
            "af2acda2257b45078ca0d6e80baaaba0",
            "84fe1b2474bf47a69fc78d854b751afd",
            "f57dfc58f21148d2a51ba43b2ac07a74"
          ]
        },
        "id": "cTSG8Nuwz2Hm",
        "outputId": "41d3afb2-01ca-4598-c791-9f4d8c501588"
      },
      "outputs": [],
      "source": [
        "metric = evaluate.load('accuracy')\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "OkSlB7ZzKb7v"
      },
      "outputs": [],
      "source": [
        "def fine_tune_classification_model(classification_model,\n",
        "                                   tokenizer,\n",
        "                                   train_data,\n",
        "                                   dev_data,\n",
        "                                   batch_size = 16,\n",
        "                                   num_epochs = 2):\n",
        "    \"\"\"\n",
        "    Preprocess the data using the given tokenizer (we've give you the code for that part).\n",
        "    Create the training arguments and trainer for the given model and data (write your code for that).\n",
        "    Then train it.\n",
        "    \"\"\"\n",
        "\n",
        "    preprocessed_train_data = train_data.map(preprocess_imdb, batched=True, fn_kwargs={'tokenizer': tokenizer})\n",
        "    preprocessed_dev_data = dev_data.map(preprocess_imdb, batched=True, fn_kwargs={'tokenizer': tokenizer})\n",
        "\n",
        "    ### YOUR CODE HERE\n",
        "\n",
        "    # training_args = ...\n",
        "    # trainer = ...\n",
        "\n",
        "\n",
        "\n",
        "    ### END YOUR CODE\n",
        "\n",
        "    trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkolanVUpoXR"
      },
      "source": [
        "Let's try BERT-base-case first, the same model that was used in the lesson 4 notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258,
          "referenced_widgets": [
            "02027c7c107f48be99e1847390967a5f",
            "ff011492882c44efadf2e20b4218307a",
            "6656beb6450b469f9f2efc471f9d051e",
            "1deefe466ac34e869963fcce2bbc68ba",
            "fefc09b9d5904959a1b6983d62e30655",
            "9ba1e940a0074d8e95118d95f7effc4b",
            "e122ff7f85014195a5b358fec1a46840",
            "c78ca0a16d034501b0f0dc6a2fd55133",
            "1e8ea092a85b4e2e9dc9f55fb7d69dc7",
            "72e0ab1c5c11471eaafc6acef73de561",
            "3bc79348f1664ca8aed0018ccfed1632",
            "0d66141d3fee4c739a63ee6d595ac858",
            "1bb990962db74421974e8388d6d296ec",
            "c703a39c5e52470cba9b5bd9e781f210",
            "681cf02421554d62a874dfeed7f4d6e9",
            "2b135e2fea724e7e804e07661fd99fe7",
            "c2afdba533b441a0aae5b1d92808fd14",
            "acd07beb46704d01a08e641454ecd4d7",
            "7a84ff20dfba4ab58d24867ec94624e1",
            "9cf649d7c5674cbea140a1c9a2976c6c",
            "eabef13366024a3f84e2a6bf375207eb",
            "261812e51a974c4abb31a1b2d87378a1"
          ]
        },
        "id": "uC1ovEW5pmGy",
        "outputId": "86b6623b-9f04-4e27-b44c-6d92e05bb9d0"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Show the output from training BERT-base-cased on the IMDB movie reviews dataset.\n",
        "\"\"\"\n",
        "\n",
        "model_checkpoint_name = \"bert-base-cased\"\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(model_checkpoint_name)\n",
        "bert_classification_model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint_name)\n",
        "\n",
        "fine_tune_classification_model(bert_classification_model, bert_tokenizer, imdb_train_dataset, imdb_dev_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcK2PyPNoNc2"
      },
      "source": [
        "Often, one of the first choices you have is what pre-trained model you'll want to use. There are quite a few options, especially because other researchers and practitioners fine-tune their own versions of existing models and sometimes make theirs available for others to continue building on.\n",
        "\n",
        "You can search through models available on [Huggingface at this website](https://huggingface.co/models?pipeline_tag=text-classification&sort=trending). Some models were made by Huggingface or other large companies/organizations; other models may have been uploaded by individual users. Notice the search tags on the left, we've already clicked the tag for \"Text Classification\" in the link above. You should see various versions of BERT-style models.\n",
        "\n",
        "For our IMDB classification, we might want to try a model that has been trained on another dataset related to sentiment or emotions. We also want to find models that have a complete model card with documentation about the model architecture and how it was trained, and potentially a link to an associated research paper, and/or a good number of downloads and likes.\n",
        "\n",
        "Take a look at this model: [cardiffnlp/twitter-roberta-base-sentiment](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment). It's a RoBERTa model (similar to BERT with slightly different pre-training, often popular for classification tasks), that has already been fine-tuned on the TweetEval benchmark set of tasks for sentiment analysis.\n",
        "\n",
        "The model card indicates that there is an updated version of this model now available. Follow the link to the latest version of the model, and look at that most recent model's card to answer the following questions. Then load that most recent model to train on our task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-Exxp4UqAMV"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        " 2.a What is the model checkpoint name for the most recent version of this Twitter Roberta-base sentiment analysis model? (Copy and paste the model checkpoint name into the answers file. It should be the full name that you put inside the quotes to load the file below.)\n",
        "\n",
        " **QUESTION:**\n",
        "\n",
        " 2.b Approximately how many tweets was this latest model trained on? (Put the answer in the answers file. You can use the abbreviation for millions like in the model card, e.g. a number like 12M or 85M.)\n",
        "\n",
        " **QUESTION:**\n",
        "\n",
        " 2.c What is the title of the published reference paper for this most recent model? (Copy the full title of the paper and paste it into the answers file.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468,
          "referenced_widgets": [
            "97f9b7626665442c9693bf77ac46d633",
            "a6e1ab2d97a7433b9223420dbc5ab909",
            "3736207e337e4d6abbfc9b14ea849601",
            "c989f94a2c5b4249bea91ec689d237cd",
            "5e760a5ba75d44dfbaf9ce53007eb1f4",
            "e43c39014f17496484ed1904ead18902",
            "912fda73a85f4e3bae8c09774144a33e",
            "b910372d53ac4f25802f8c3367b28b9f",
            "82e16645079b47cbbe1749530743c4db",
            "817008fcf69c4363bff746ea4d754d5f",
            "f1bcbccd80f64380aaec560a5b9de6d4",
            "7b6a62f5538247d4b6eb0158fb640c88",
            "5b727cef9d08465ea28dc0bc196a5ff1",
            "cfe66c8b287944d6908b65e9b427765c",
            "f2705b6f95e0458b9f6e6ecb4ea5bed5",
            "ad8ea545f6b4473796a65b9612fa1472",
            "8531f69df46f44719292312b28ec00c8",
            "68a2692778a64199a3615efd66acff29",
            "66422d6f353240b4a78b278c0be72bd0",
            "837948135c9944098a8d940550fede4f",
            "1cafe2dc22f04d4782b6a7890307166b",
            "90d2852724dc422882d119a22944222f",
            "16fedebe2a704944a0c0dd01e9db9be8",
            "f5dd0768f90847b3bfac6a8da5849a43",
            "064a5807e9274a6787b240800353554e",
            "ca90b99abe5e46cb82dda66f0a6db22f",
            "bf12bd5319f048f68ef74b3a713a7380",
            "0e8e07e98da14a9c992b62af313ca5cb",
            "46bb36c4a7da4b16a3926e077879ef7e",
            "2697863ce14d472c961e3a616e0f0e3a",
            "726366f948a240879d22b332ce10dc88",
            "6191e1996ba841f9a64941e44231d736",
            "d7256d28151240ef87ab72c180a4d9f0",
            "d7a12cd943b746bfbce070102e09aba0",
            "6eb6d570bdb74b49892031250e7422d2",
            "aab805e1de7c42dda9c6f437ac16eb36",
            "f8f026b717cd416e87631f83199537ad",
            "b6e4e133077948c1a95569b01cdb62d2",
            "73c06f75e1264171b1fb2e9e57ce586f",
            "9a09161e1b4440728b8deae3ac62b25f",
            "4eda733d73ea457d86c84610023a4f15",
            "640a969de13b411faada1f9019f85467",
            "97ec564408754d91ab572aa3389e4d53",
            "9e283f490a8145ad9920585570f5f188",
            "7c12313f912846e5aa752fb212bdde5c",
            "edc153f6eef24298b8a74b9c15d7d611",
            "54a9441d4cbc4b2880064d4f25729b81",
            "2f2fb3e4fa614929b545eccc44bc3fea",
            "820777ffcbb9405ba9f935cbf69c6ec8",
            "7443372201594467ab2445bdcf8117a9",
            "65f5d063305840bf8ff31dc638580006",
            "a1e092b4bea844ffaff9b1e5d5f676bb",
            "3f35c71b143c48de9786f97b73adb88b",
            "c7abde081423434a9dd0b27e333c0c89",
            "55cbf37e2bc34c66af251ace6ce598f7",
            "31e0fc2b858947318e999cd62a323fdf",
            "49e5fafe17a74b1da4f56d1fec0cfd97",
            "0f7cc71cc7054b70b7e8733bec0344cc",
            "bff0ae38f4e244bc96314bc7e4fffe3c",
            "24a223fab68c4589ba27969d578386c5",
            "9ea841f6f7864db48535d7a5cecc523e",
            "5317df881070494bbf6fbd9603b6bac2",
            "6082f47ee4b7440a9989bfd3be6a0448",
            "cd3e9471273f458589de25a0c52be6bd",
            "a9aa3acc830f4e949c242fb739bb2690",
            "ba997b1675c74c7f9fdca7f574740452",
            "70da49e8c62d42ca8cbafd748c31a245",
            "1fd70d82799d4568974bcb89ef9f76a6",
            "e7cb8800e6794fb4b19cfd59e3fd6e83",
            "effec6cb4b0f45d0b58aa3504c90d722",
            "74ff956707bf45b7ac205b13bc8e3f2a",
            "a81b84dd0a1b4e72a70749905aab907b",
            "0cd5d5ed77544adda00cc1c40f0c21d7",
            "47fca7b7d14d416481a686ea2f2912ed",
            "6a846b52545542b8ae355114ba2214db",
            "20e00e99fbbf4c93adfb668b71358814",
            "692539ef5b73450db95ea45c347b584f",
            "63657b4227764f37aa5ba02dce62829b",
            "7de7780a684846e787ba22b87bc5858e",
            "7db0e04492914a3bb913fbca046bb8d5",
            "d0aa148094af452d970b44a40e579657",
            "06847c78dde5405083b03ec584639e39",
            "5a7446abaada442aac7cd5ec4f25fd05",
            "00f002c1ce0746b7b15cd00c651e38de",
            "9e6fcd54c0cb4e079f3938633022b049",
            "19537b13a600480d99e763fda9c58f9d",
            "7b7b5e2c51074b6da55c89f28851e63c",
            "4fe2f9d320c14d468114d5d79f3025e4"
          ]
        },
        "id": "p9VO4fPfTsQV",
        "outputId": "2d8cfdd9-023d-4da3-d264-9b36a83824b3"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Show the output from training the most recent Twitter RoBERTa sentiment model on the IMDB movie reviews dataset.\n",
        "Insert the model checkpoint name for the latest version of that model below.\n",
        "\"\"\"\n",
        "\n",
        "### YOUR CODE HERE\n",
        "\n",
        "# model_checkpoint_name = ...\n",
        "\n",
        "\n",
        "### END YOUR CODE\n",
        "\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(model_checkpoint_name)\n",
        "bert_classification_model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint_name)\n",
        "\n",
        "fine_tune_classification_model(bert_classification_model, bert_tokenizer, imdb_train_dataset, imdb_dev_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLjgxylMnC0x"
      },
      "source": [
        "**QUESTION:**\n",
        "\n",
        "2.d What is the final validation accuracy that you observed for the Twitter RoBERTa sentiment-trained model after training for 2 epochs? (Copy and paste the decimal value for the final validation accuracy, e.g. a number like 0.567 or 0.876. Use up to 5 significant digits, though fewer is fine if the output shown in the notebook only has 3 or 4. Put the answer in the answers file; it should match the value shown in your output in this notebook.)\n",
        "\n",
        "**QUESTION:**\n",
        "\n",
        "2.e Did the Twitter RoBERTa sentiment-trained model do better or worse or the same as the BERT-base?\n",
        "\n",
        "\n",
        "**(Answer 2.f below but do NOT enter your sentences in the answers file)**\n",
        "\n",
        "**QUESTION:**\n",
        "\n",
        "2.f Why do you think that happened? (Put your two to three sentence answer in the cell below.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrzZGZyFsz6K"
      },
      "source": [
        "Please answer 2.f in two to three sentences right here:\n",
        "\n",
        "** BEGIN Q 2.f ANSWER HERE **\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "** END Q 2.f ANSWER HERE. **\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cMVEBuxro4j"
      },
      "source": [
        "### 3. Unfreezing Different Pre-Trained Layers\n",
        "\n",
        "In the lesson 4 notebook, we tested freezing most or all of the pre-trained BERT model layers. We used the .named_parameters() method, looking at the specific names of each set of model parameters.\n",
        "\n",
        "As in the lesson notebook, we will always want to make sure we keep the classification layer parameters unfrozen, since those need to be trained for our specific task. We will also keep the pooler layer unfrozen, since it's next closest to the classification layer and was only pre-trained in standard BERT models with the next sentence prediction task.\n",
        "\n",
        "For the remaining layers, what happens if we unfreeze lower transformer blocks and keep higher transformer blocks frozen (the opposite of what we did in the lesson notebook)? What if we instead try unfreezing specific types of layers within each transformer block, e.g. all of the self attention layers, or all of the dense layers?\n",
        "\n",
        "Let's modify our fine-tuning function, to add an argument for the layers that we want to train. We'll make that argument a list of strings, and we'll set the default to just unfreeze the classification layer. You'll need to write the code to compare those strings to the names of the model parameters (after loading the specified model) and freeze all parameters that don't match (as in the lesson 4 notebook)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNwvUHJvbjFy",
        "outputId": "51e490a7-c4cd-479a-a35c-f9943a93d0d3"
      },
      "outputs": [],
      "source": [
        "# Refresh your memory on what the parameter names look like\n",
        "for name, param in bert_classification_model.named_parameters():\n",
        "    print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "SRlDR1jaaBEj"
      },
      "outputs": [],
      "source": [
        "def fine_tune_classif_model_freeze_layers(classification_model,\n",
        "                                          tokenizer,\n",
        "                                          train_data,\n",
        "                                          dev_data,\n",
        "                                          layers_to_train = [\"classifier.\"],\n",
        "                                          max_sequence_length=MAX_SEQUENCE_LENGTH,\n",
        "                                          batch_size = 16,\n",
        "                                          num_epochs = 2):\n",
        "    \"\"\"\n",
        "    Freeze any parameters inside the given model that have a name containing one of the\n",
        "    strings in the \"layers_to_freeze\" list.\n",
        "    Then specify the training arguments and trainer for the given model and data.\n",
        "    Then train it.\n",
        "    \"\"\"\n",
        "\n",
        "    preprocessed_train_data = train_data.map(preprocess_imdb, batched=True, fn_kwargs={'tokenizer': tokenizer})\n",
        "    preprocessed_dev_data = dev_data.map(preprocess_imdb, batched=True, fn_kwargs={'tokenizer': tokenizer})\n",
        "\n",
        "    ### YOUR CODE HERE\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ### END YOUR CODE\n",
        "\n",
        "    trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcLrgI49tBde"
      },
      "source": [
        "We'll go back to using bert-base-cased for this part. First, try freezing the parameters in transformer layers 1-11 (including all parameters with \"layer.#\" in the name). That means you're leaving unfrozen the initial embedding layers, the first transformer layer (numbered 0), and the classification layer.\n",
        "\n",
        "Unfreezing the bottom transformer layer(s) rather than the top one(s) is uncommon, but it's always good to try to understand why. Since we're learning, we'll try doing it this way and see what happens. We've given you the code for this exercise, so that the way to specify layers_to_freeze is clear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226,
          "referenced_widgets": [
            "ffc36a4114c94642a6914af9d631e0a3",
            "295e11948a06457a9e21c3fe39852151",
            "348295211b3b4678b0c7480a12300e62",
            "8e01ef0887fe41979c0eb1cddd91b673",
            "7deeacde4eb54fd0bf9841ec0b9eade7",
            "aee159e97c4a4a9bb4a7652c0166f383",
            "30ba529e368e43e49300dbf553d0097c",
            "0810def4ced24f32a10635fc69c9832b",
            "6ed67061e3af4434b0cf57dcf4f349fd",
            "461573cf5d8c4ffb8ce5600cf0d168c2",
            "e9c6cb0f280743b281e57dc9518f8fbf"
          ]
        },
        "id": "AtS29uRbk4Os",
        "outputId": "7a65cac7-8e9f-4bb2-c448-ea50a70e1c20"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Show the output from training a BERT-base-cased classification model, when unfreezing\n",
        "only the parameters in the embedding layers, first transformer layer (layer 0), and classifier layer.\n",
        "\"\"\"\n",
        "\n",
        "model_checkpoint_name = \"bert-base-cased\"\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(model_checkpoint_name)\n",
        "bert_classification_model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint_name)\n",
        "\n",
        "layers_to_train = [\"embeddings.\", \"layer.0.\", \"classifier.\"]\n",
        "\n",
        "fine_tune_classif_model_freeze_layers(\n",
        "    bert_classification_model,\n",
        "    bert_tokenizer,\n",
        "    imdb_train_dataset,\n",
        "    imdb_dev_dataset,\n",
        "    layers_to_train\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiWb3y9anNlG"
      },
      "source": [
        " **QUESTION:**\n",
        "\n",
        "3.a What is the final validation accuracy that you observed for this lowest level unfrozen version of the BERT classification model after training for 2 epochs? (Copy and paste the decimal value into the answers file, as instructed in 2.b)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CgRacR2cyku"
      },
      "source": [
        "Now try two more versions, this time choosing which layers to train yourself. Instead of focusing on the number of the transformer block (layer.#), focus on the type of layer within each block (the stuff that comes after layer.# in the name).\n",
        "\n",
        "Keep the pooler and classification layers unfrozen in all model versions. Your options to also train include the initial embedding layers and the different components within the transformer blocks (e.g. self attention matrices, dense layers, layer norms).\n",
        "\n",
        "Try to find one combination that does better than the version you just ran above (higher validation accuracy after 2 epochs), without much more overfitting (training_loss / eval_loss > 0.7). Also try to find one version that overfits a lot more after 2 epochs (training_loss / eval_loss < 0.5)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "UC5rFV2ocyqd",
        "outputId": "2e85e85b-3559-441e-c6ec-3f1be9b0152f"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Show the output from training a particular model on the IMDB movie reviews dataset.\n",
        "Choose layers to train that lead the model to perform better than the one in question 3.a, without overfitting much more.\n",
        "\"\"\"\n",
        "\n",
        "model_checkpoint_name = \"bert-base-cased\"\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(model_checkpoint_name)\n",
        "bert_classification_model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint_name)\n",
        "\n",
        "### YOUR CODE HERE\n",
        "\n",
        "# layers_to_train = [...]    #ANY STRINGS THAT MATCH SOME LAYERS ARE OK\n",
        "\n",
        "\n",
        "### END YOUR CODE\n",
        "\n",
        "\n",
        "fine_tune_classif_model_freeze_layers(\n",
        "    bert_classification_model,\n",
        "    bert_tokenizer,\n",
        "    imdb_train_dataset,\n",
        "    imdb_dev_dataset,\n",
        "    layers_to_train\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0F7EnTzcy1r"
      },
      "source": [
        " **QUESTION:**\n",
        "\n",
        "3.b What is the final training loss that you observed for this better performing version of the BERT classification model after training for 2 epochs? (Copy and paste the decimal value into the answers file, as instructed in 2.b)\n",
        "\n",
        "3.c What is the final validation loss that you observed for this better performing version of the BERT classification model after training for 2 epochs? (Copy and paste the decimal value into the answers file, as instructed in 2.b)\n",
        "\n",
        "3.d What is the ratio of your final training loss/final validation loss? For this better version the ratio must be greater than 0.7.\n",
        "\n",
        "3.e What is the final validation accuracy that you observed for this better performing version of the BERT classification model after training for 2 epochs? (Copy and paste the decimal value into the answers file, as instructed in 2.b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "4GR6YpCZesdi",
        "outputId": "c3a5e919-032f-40d1-ae18-e6de35f9ed88"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Show the output from training a particular model on the IMDB movie reviews dataset.\n",
        "Choose layers to train that lead the model to overfit.\n",
        "\"\"\"\n",
        "\n",
        "model_checkpoint_name = \"bert-base-cased\"\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(model_checkpoint_name)\n",
        "bert_classification_model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint_name)\n",
        "\n",
        "### YOUR CODE HERE\n",
        "\n",
        "# layers_to_train = [...]\n",
        "\n",
        "\n",
        "### END YOUR CODE\n",
        "\n",
        "\n",
        "fine_tune_classif_model_freeze_layers(\n",
        "    bert_classification_model,\n",
        "    bert_tokenizer,\n",
        "    imdb_train_dataset,\n",
        "    imdb_dev_dataset,\n",
        "    layers_to_train\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkZ3k_s3gEAa"
      },
      "source": [
        " **QUESTION:**\n",
        "\n",
        "3.f What is the final training loss that you observed for this overfitting version of the BERT classification model after training for 2 epochs? (Copy and paste the decimal value into the answers file, as instructed in 2.b)\n",
        "\n",
        "3.g What is the final validation loss that you observed for this overfitting version of the BERT classification model after training for 2 epochs? (Copy and paste the decimal value into the answers file, as instructed in 2.b)\n",
        "\n",
        "3.h What is the ratio of your final training loss/final validation loss? For this overfitting version the ratio must be less than 0.5.\n",
        "\n",
        "3.i What is the final validation accuracy that you observed for this overfitting version of the BERT classification model after training for 2 epochs? (Copy and paste the decimal value into the answers file, as instructed in 2.b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y3e9X8bvhZf"
      },
      "source": [
        "## Congratulations... You are done!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "state": {},
        "version_major": 2,
        "version_minor": 0
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
